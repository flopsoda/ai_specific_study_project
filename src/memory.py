import os
from typing import List
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from config import STORY_CONTEXT_WINDOW

class LoreBook:
    def __init__(self):
        # 1. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ (í…ìŠ¤íŠ¸ -> ìˆ«ì ë³€í™˜ê¸°)
        self.embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        
        # 2. ë²¡í„° ì €ì¥ì†Œ (ì•„ì§ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ None)
        self.vector_store = None
        
        # 3. [í•µì‹¬] ì±…ê°ˆí”¼ (ì–´ë””ê¹Œì§€ ì €ì¥í–ˆëŠ”ì§€ ê¸°ì–µí•˜ëŠ” ì»¤ì„œ)
        self.last_archived_index = 0

    def check_and_archive(self, story_parts: List[str]):
        """
        ì „ì²´ ì´ì•¼ê¸° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ, ìœˆë„ìš° ë°–ìœ¼ë¡œ ë°€ë ¤ë‚œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì €ì¥í•©ë‹ˆë‹¤.
        """
        total_length = len(story_parts)
        
        # ì €ì¥í•´ì•¼ í•  í•œê³„ì„  (Boundary) ê³„ì‚°
        # ì˜ˆ: ì „ì²´ 10ê°œ, ìœˆë„ìš° 5ê°œ -> ì¸ë±ìŠ¤ 5ê¹Œì§€ëŠ” ì €ì¥í•´ì•¼ í•¨ (0,1,2,3,4)
        boundary_index = total_length - STORY_CONTEXT_WINDOW
        
        # ì €ì¥í•  ê²Œ ì—†ë‹¤ë©´(ì•„ì§ ìœˆë„ìš° ì•ˆìª½ì´ë¼ë©´) íŒ¨ìŠ¤
        if boundary_index <= self.last_archived_index:
            return

        # --- ì €ì¥ ë¡œì§ ì‹œì‘ ---
        print(f"\nğŸ“š [LoreBook] ì •ë¦¬í•  ë¬¸ë‹¨ ë°œê²¬! (ì¸ë±ìŠ¤ {self.last_archived_index} ~ {boundary_index})")
        
        # 1. ì €ì¥í•  ë¬¸ë‹¨ë“¤ë§Œ ì™ ë½‘ì•„ë‚´ê¸° (Slicing)
        chunks_to_archive = story_parts[self.last_archived_index : boundary_index]
        
        # 2. ë²¡í„° DBì— ë„£ê¸°
        self._add_documents(chunks_to_archive)
        
        # 3. [í•µì‹¬] ì±…ê°ˆí”¼ ì—…ë°ì´íŠ¸ (ì´ì œ ì—¬ê¸°ê¹Œì§€ ì €ì¥í–ˆë‹¤ê³  í‘œì‹œ)
        self.last_archived_index = boundary_index
        print(f"âœ… [LoreBook] ì €ì¥ ì™„ë£Œ. í˜„ì¬ ì»¤ì„œ ìœ„ì¹˜: {self.last_archived_index}")

    def _add_documents(self, texts: List[str]):
        """ì‹¤ì œë¡œ FAISS DBì— ë°ì´í„°ë¥¼ ë„£ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""
        if not texts:
            return
            
        # í…ìŠ¤íŠ¸ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜ (ë©”íƒ€ë°ì´í„° ì¶”ê°€ ê°€ëŠ¥)
        documents = [
            Document(page_content=text, metadata={"source": "story_archive"})
            for text in texts
        ]
        
        if self.vector_store is None:
            # DBê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            self.vector_store = FAISS.from_documents(documents, self.embeddings)
        else:
            # ìˆìœ¼ë©´ ì¶”ê°€
            self.vector_store.add_documents(documents)

    def search_relevant_info(self, query: str, k: int = 3) -> str:
        """
        í˜„ì¬ ìƒí™©(query)ê³¼ ê´€ë ¨ëœ ê³¼ê±° ê¸°ì–µì„ ê²€ìƒ‰í•´ì„œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if self.vector_store is None:
            return "ì•„ì§ ê¸°ë¡ëœ ê³¼ê±° ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤."
            
        # ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰
        try:
            docs = self.vector_store.similarity_search(query, k=k)
            # ê²€ìƒ‰ëœ ë‚´ìš©ë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
            result = "\n".join([f"- {doc.page_content}" for doc in docs])
            return result
        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return ""

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì–´ë””ì„œë“  ë¶ˆëŸ¬ë‹¤ ì“¸ ìˆ˜ ìˆê²Œ)
lore_book = LoreBook()