from cmath import phase
import os
from typing import List, TypedDict, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
import asyncio

from config import CHARACTERS, MAIN_WRITER_CONFIG, CHARACTER_AGENT_CONFIG, JUDGE_CONFIG 
from shared import global_state
from langgraph.graph import END
from utils import get_story_context
from memory import lore_book


# --- ê·¸ë˜í”„ì˜ ìƒíƒœ(State) ì •ì˜ ---
class GraphState(TypedDict):
    # ê¸°ë³¸ í•„ë“œ
    story_parts: List[str]
    current_context: str
    retrieved_memory: str
    discussion: List[str]
    selected_character: str
    user_decision: Optional[str]
    # ì´ˆì•ˆ/ë¹„í‰ ìˆœí™˜ ê´€ë ¨ í•„ë“œ
    draft: Optional[str]
    revision_history: List[str]
    revision_count: int
    phase: str                       # "ideation" | "critique"
    judge_result: Optional[str]      # "pass" | "revise"


# --- LLM ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
WRITER_LLM = ChatGoogleGenerativeAI(
    model=MAIN_WRITER_CONFIG["model"],
    temperature=MAIN_WRITER_CONFIG["temperature"]
)

JUDGE_LLM = ChatGoogleGenerativeAI(
    model=JUDGE_CONFIG["model"],
    temperature=JUDGE_CONFIG["temperature"]
)

VOTE_LLM = ChatGoogleGenerativeAI(
    model=CHARACTER_AGENT_CONFIG["vote_model"],
    temperature=CHARACTER_AGENT_CONFIG["vote_temperature"]
)

OPINION_LLM = ChatGoogleGenerativeAI(
    model=CHARACTER_AGENT_CONFIG["opinion_model"],
    temperature=CHARACTER_AGENT_CONFIG["opinion_temperature"]
)


# --- ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ---

# --- ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ë…¸ë“œ ---
async def check_continuation(state: GraphState):
    """ì›¹ UIì—ì„œ ì‚¬ìš©ìì˜ ì„ íƒ(ê³„ì†/ì¢…ë£Œ)ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."""
    global_state["current_node"] = "user_input"
    global_state["current_status"] = "ë‹¹ì‹ ì˜ ì„ íƒì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤."
    global_state["waiting_for_input"] = True
    global_state["user_decision"] = None 
    global_state["user_instruction"] = None
    
    print("\nâ³ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ [ê³„ì†í•˜ê¸°] ë˜ëŠ” [ì¢…ë£Œ]ë¥¼ ì„ íƒí•˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")

    # ì›¹ì—ì„œ ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°
    while global_state["user_decision"] is None:
        await asyncio.sleep(0.5)

    decision = global_state["user_decision"]
    instruction = global_state.get("user_instruction", "")
    global_state["waiting_for_input"] = False
    
    print(f"âœ… ì‚¬ìš©ì ì„ íƒ í™•ì¸: {decision}")
    if instruction:
        print(f"ì‚¬ìš©ì ê°œì…: {instruction}")
    
    if decision == "continue":
        new_discussion = []
        if instruction:
            system_msg = f"*** [ê¸´ê¸‰ ìƒí™© ë°œìƒ] ì™¸ë¶€ì˜ ì ˆëŒ€ì ì¸ í˜ì— ì˜í•´ ë‹¤ìŒ í˜„ìƒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤: '{instruction}' ***\n(ëª¨ë“  ì‘ê°€ëŠ” ì´ ìƒí™©ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°˜ì˜í•˜ì—¬ ë‹¤ìŒ ì „ê°œë¥¼ ë…¼ì˜í•˜ì‹­ì‹œì˜¤.)"
            new_discussion.append(system_msg)
        
        # ìƒˆ ë¬¸ë‹¨ ì‚¬ì´í´ ì‹œì‘ â†’ ìƒíƒœ ì´ˆê¸°í™”
        return {
            "user_decision": decision,
            "discussion": new_discussion,
            "draft": None,
            "revision_history": [],
            "revision_count": 0,
            "phase": "ideation",
            "judge_result": None
        }
        
    return {"user_decision": decision}


# --- ë¼ìš°íŒ… í•¨ìˆ˜ ---
def route_continuation(state: GraphState):
    """ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    decision = global_state.get("user_decision")
    
    if decision == "continue":
        return "race_for_action"
    else:
        return END


# --- RAG ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë…¸ë“œ ---
def retrieve_memory_node(state: GraphState) -> dict:
    """ì´ë²ˆ í„´ì— í•„ìš”í•œ ê³¼ê±° ê¸°ì–µì„ LoreBookì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    global_state["current_node"] = "memory"
    print("\n[System] ì´ë²ˆ í„´ì— í•„ìš”í•œ ê³¼ê±° ê¸°ì–µì„ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    
    query = state.get("current_context", "")
    if not query:
        query = get_story_context(state["story_parts"])
        
    memory = lore_book.search_relevant_info(query)
    
    if memory and "ì•„ì§ ê¸°ë¡ëœ" not in memory:
        print(f"ğŸ” ê²€ìƒ‰ëœ ê¸°ì–µ: {memory[:50]}...")
    else:
        print("ğŸ” ê²€ìƒ‰ëœ ê¸°ì–µ ì—†ìŒ (ì´ˆë°˜ì´ê±°ë‚˜ ë°ì´í„° ë¶€ì¡±)")
        
    return {"retrieved_memory": memory}


# --- ë°œì–¸ê¶Œ ê²½ìŸ í—¬í¼ í•¨ìˆ˜ ---
async def _get_character_vote(
    character_name: str, 
    story_so_far: str, 
    discussion: List[str], 
    context: str, 
    phase: str, 
    draft: str, 
    revision_history_str: str
) -> Optional[str]:
    """ë‹¨ì¼ ìºë¦­í„°ì˜ íˆ¬í‘œë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì–»ëŠ” í—¬í¼ í•¨ìˆ˜"""
    discussion_str = "\n".join(discussion)
    character_config = CHARACTERS[character_name]
    character_prompt = character_config["prompt"]

    # phaseì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    if phase == "ideation":
        prompt = CHARACTER_AGENT_CONFIG["prompt_templates"]["vote"].format(
            character_name=character_name,
            character_prompt=character_prompt,
            context=context,
            story_so_far=story_so_far,
            discussion_str=discussion_str
        )
    else:  # critique
        prompt = CHARACTER_AGENT_CONFIG["prompt_templates"]["vote_critique"].format(
            character_name=character_name,
            character_prompt=character_prompt,
            context=context,
            story_so_far=story_so_far,
            draft=draft,
            discussion_str=discussion_str,
            revision_history_str=revision_history_str
        )
    
    try:
        response = await VOTE_LLM.ainvoke(prompt)
        vote = response.content.strip() 
        if "ë„¤" in vote:
            return character_name
    except Exception as e:
        print(f"--- {character_name} íˆ¬í‘œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} ---")
        return None
    return None


# --- ë°œì–¸ê¶Œ ê²½ìŸ ë…¸ë“œ ---
async def race_for_action(state: GraphState) -> dict:
    """ëª¨ë“  ìºë¦­í„°ì—ê²Œ ë™ì‹œì— ë¬¼ì–´ë³´ê³ , ê°€ì¥ ë¨¼ì € 'ë„¤'ë¼ê³  ë‹µí•˜ëŠ” ìºë¦­í„°ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
    global_state["current_node"] = "race_for_action"
    
    phase = state.get("phase", "ideation")
    phase_display = "1ì°¨ íšŒì˜ (ì•„ì´ë””ì–´)" if phase == "ideation" else "ë¹„í‰ íšŒì˜"
    global_state["current_status"] = f"ğŸ‘€ [{phase_display}] ëˆ„ê°€ ë°œì–¸í• ì§€ ê²½ìŸ ì¤‘)"
    global_state["phase"] = phase

    story_so_far = state.get("current_context", "")
    context = state.get("retrieved_memory", "")
    draft = state.get("draft", "")
    revision_history = state.get("revision_history", [])
    revision_history_str = "\n---\n".join(revision_history) if revision_history else "(ì´ì „ ë¹„í‰ ì—†ìŒ)"
    discussion = state["discussion"]
        
    characters = list(CHARACTERS.keys())
    tasks = [
        asyncio.create_task(
            _get_character_vote(name, story_so_far, discussion, context, phase, draft, revision_history_str)
        ) 
        for name in characters
    ]
    
    winner = None
    for future in asyncio.as_completed(tasks):
        try:
            result = await future
            if result:
                winner = result
                break
        except asyncio.CancelledError:
            pass
    
    # ìŠ¹ìê°€ ê²°ì •ë˜ë©´ ë‚˜ë¨¸ì§€ ì‘ì—… ì·¨ì†Œ
    for task in tasks:
        if not task.done():
            task.cancel()
            
    if not winner:
        print("--- í–‰ë™í•˜ë ¤ëŠ” ìºë¦­í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ---")
        return {"selected_character": "None"}
    
    return {"selected_character": winner}


# --- ìºë¦­í„° ì˜ê²¬ ìƒì„± ë…¸ë“œ ---
def generate_character_opinion(state: GraphState) -> dict:
    """ì„ íƒëœ ìºë¦­í„°ê°€ í† ë¡ ì— ëŒ€í•œ ì˜ê²¬ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    global_state["current_node"] = "generate_opinion"
    
    character_name = state["selected_character"]
    phase = state.get("phase", "ideation")
    phase_display = "1ì°¨ íšŒì˜" if phase == "ideation" else "ë¹„í‰ íšŒì˜"
    global_state["current_status"] = f"ğŸ—£ï¸ [{phase_display}] '{character_name}' ì‘ê°€ê°€ ë°œì–¸ì„ ì •ë¦¬í•˜ëŠ” ì¤‘..."

    if not character_name or character_name == "None":
        return {}

    story_so_far = state.get("current_context", "")
    context = state.get("retrieved_memory", "")
    discussion = state["discussion"]
    discussion_str = "\n".join(discussion)
    character_config = CHARACTERS[character_name]
    
    draft = state.get("draft", "")
    revision_history = state.get("revision_history", [])
    revision_history_str = "\n---\n".join(revision_history) if revision_history else "(ì´ì „ ë¹„í‰ ì—†ìŒ)"
    
    # phaseì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    if phase == "ideation":
        prompt = CHARACTER_AGENT_CONFIG["prompt_templates"]["generate_opinion"].format(
            character_name=character_name,
            character_prompt=character_config["prompt"],
            context=context,
            story_so_far=story_so_far,
            discussion_str=discussion_str
        )
    else:  # critique
        prompt = CHARACTER_AGENT_CONFIG["prompt_templates"]["generate_opinion_critique"].format(
            character_name=character_name,
            character_prompt=character_config["prompt"],
            context=context,
            story_so_far=story_so_far,
            draft=draft,
            discussion_str=discussion_str,
            revision_history_str=revision_history_str
        )

    response = OPINION_LLM.invoke(prompt)
    opinion = f"[{character_name} íŒŒíŠ¸ ë‹´ë‹¹ ì‘ê°€]: {response.content.strip()}" 
    print(opinion)
    
    return {"discussion": discussion + [opinion]}


# --- ë©”ì¸ ì‘ê°€ ë…¸ë“œ ---
def main_writer_node(state: GraphState) -> dict:
    """ì§€ê¸ˆê¹Œì§€ì˜ íšŒì˜ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì´ˆì•ˆì„ ì‘ì„±í•˜ê±°ë‚˜ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    global_state["current_node"] = "main_writer"
    print("\n--- ë©”ì¸ ì‘ê°€ ì—ì´ì „íŠ¸ ì‘ë™ ---")
    
    phase = state.get("phase", "ideation")
    story_so_far = state.get("current_context", "")
    context = state.get("retrieved_memory", "")
    discussion_str = "\n".join(state["discussion"])
    
    # phaseì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    if phase == "ideation":
        global_state["current_status"] = "ë©”ì¸ ì‘ê°€ê°€ ì´ˆì•ˆì„ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
        print("\n--- ë©”ì¸ ì‘ê°€: ì´ˆì•ˆ ì‘ì„± ì¤‘ ---")
        
        prompt = MAIN_WRITER_CONFIG["prompt_template"].format(
            world_name=MAIN_WRITER_CONFIG["world_name"],
            world_description=MAIN_WRITER_CONFIG["world_description"],
            context=context,
            story_so_far=story_so_far,
            discussion_str=discussion_str
        )
    else:
        global_state["current_status"] = "ë©”ì¸ ì‘ê°€ê°€ ì´ˆì•ˆì„ ìˆ˜ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
        print("\n--- ë©”ì¸ ì‘ê°€: ì´ˆì•ˆ ìˆ˜ì • ì¤‘ ---")
        
        prompt = MAIN_WRITER_CONFIG["prompt_template_revise"].format(
            world_name=MAIN_WRITER_CONFIG["world_name"],
            world_description=MAIN_WRITER_CONFIG["world_description"],
            context=context,
            story_so_far=story_so_far,
            current_draft=state.get("draft", ""),
            critique_str=discussion_str
        )

    response = WRITER_LLM.invoke(prompt)
    new_draft = response.content.strip()
    new_draft = new_draft.replace("[ìˆ˜ì •ëœ ì´ì•¼ê¸°]", "").strip()
    print(f"\n[ë©”ì¸ ì‘ê°€] ê²°ê³¼:\n{new_draft[:100]}...\n")
    
    # revision_historyëŠ” ë¹„í‰ íšŒì˜(critique) ë‚´ìš©ë§Œ ëˆ„ì 
    current_history = state.get("revision_history", [])
    if phase == "critique":
        updated_history = current_history + state["discussion"]
    else:
        updated_history = current_history
    
    # ì›¹ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
    global_state["draft"] = new_draft
    global_state["revision_count"] = state.get("revision_count", 0) + 1
    
    return {
        "draft": new_draft,
        "revision_history": updated_history,
        "discussion": [],
        "phase": "critique",
        "revision_count": state.get("revision_count", 0) + 1
    }


# --- ì‹¬ì‚¬ ë…¸ë“œ ---
def judge_node(state: GraphState) -> dict:
    """ë¹„í‰ íšŒì˜ ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  í†µê³¼ ë˜ëŠ” ìˆ˜ì • í•„ìš” ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤."""
    global_state["current_node"] = "judge"
    global_state["current_status"] = "í¸ì§‘ì¥ì´ ì´ˆì•ˆì„ ì‹¬ì‚¬ ì¤‘..."
    print("\n--- í¸ì§‘ì¥: ì´ˆì•ˆ ì‹¬ì‚¬ ì¤‘ ---")
    
    draft = state.get("draft", "")
    discussion = state.get("discussion", [])
    critique_str = "\n".join(discussion) if discussion else "(ë¹„í‰ ì—†ìŒ - ëª¨ë‘ ë§Œì¡±)"
    
    # ë¹„í‰ íšŒì˜ì—ì„œ ì•„ë¬´ë„ ë°œì–¸ ì•ˆ í–ˆìœ¼ë©´ ìë™ í†µê³¼
    if not discussion:
        print("[í¸ì§‘ì¥] ë¹„í‰ íšŒì˜ì—ì„œ ì´ì˜ ì—†ìŒ â†’ ìë™ í†µê³¼!")
        return {"judge_result": "pass"}
    
    prompt = JUDGE_CONFIG["prompt_template"].format(
        draft=draft,
        critique_str=critique_str
    )
    
    response = JUDGE_LLM.invoke(prompt)
    result = response.content.strip()
    
    if "í†µê³¼" in result:
        print("[í¸ì§‘ì¥] ì´ˆì•ˆ ìŠ¹ì¸!")
        return {"judge_result": "pass"}
    else:
        print("[í¸ì§‘ì¥] ìˆ˜ì • í•„ìš”")
        return {"judge_result": "revise"}


# --- ë¬¸ë‹¨ í™•ì • ë…¸ë“œ ---
def finalize_node(state: GraphState) -> dict:
    """ì‹¬ì‚¬ë¥¼ í†µê³¼í•œ draftë¥¼ story_partsì— ì¶”ê°€í•˜ê³ , ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global_state["current_node"] = "finalize"
    global_state["current_status"] = "ë¬¸ë‹¨ í™•ì • ë° ì €ì¥ ì¤‘..."
    print("\n--- ë¬¸ë‹¨ í™•ì •: ì´ì•¼ê¸°ì— ì¶”ê°€ ---")
    
    draft = state.get("draft", "")
    story_parts = state.get("story_parts", [])
    
    new_story_parts = story_parts + [draft]
    new_context = get_story_context(new_story_parts)
    
    # ì›¹ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
    global_state["story_parts"] = new_story_parts
    global_state["discussion"] = []
    global_state["draft"] = None
    
    # LoreBookì— ì €ì¥ (RAG)
    lore_book.check_and_archive(new_story_parts)
    
    print(f"í˜„ì¬ê¹Œì§€ {len(new_story_parts)}ê°œì˜ ë¬¸ë‹¨ì´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return {
        "story_parts": new_story_parts,
        "current_context": new_context,
        "draft": None,
        "revision_history": [],
        "revision_count": 0,
        "phase": "ideation",
        "judge_result": None,
        "discussion": []
    }








