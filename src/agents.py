import os
from typing import List, TypedDict, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
import asyncio
from config import CHARACTERS, MAIN_WRITER_CONFIG, CHARACTER_AGENT_CONFIG
from shared import global_state
from langgraph.graph import END

# ---ê·¸ë˜í”„ì˜ ìƒíƒœ(State) ì •ì˜---
class GraphState(TypedDict):
    story_parts: List[str]  # ì§€ê¸ˆê¹Œì§€ ìƒì„±ëœ ì´ì•¼ê¸° ì¡°ê°ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    discussion : list[str]
    selected_character: str
    user_decision: Optional[str]

# [ì¶”ê°€] ë©”ì¸ ì‘ê°€ìš© LLM ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
WRITER_LLM = ChatGoogleGenerativeAI(
    model=MAIN_WRITER_CONFIG["model"],
    temperature=MAIN_WRITER_CONFIG["temperature"]
)

# ---í† ë¡  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ì•¼ê¸°ë¥¼ ì‘ì„±í•˜ëŠ” ë©”ì¸ ì‘ê°€ ì—ì´ì „íŠ¸---
def main_writer_node(state: GraphState) -> dict:
    """
    ì§€ê¸ˆê¹Œì§€ì˜ ì´ì•¼ê¸°ì™€ ìºë¦­í„°ë“¤ì˜ í† ë¡  ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ ì´ì•¼ê¸° ë‹¨ë½ì„ ì‘ì„±í•©ë‹ˆë‹¤.
    """
    # [ì¶”ê°€] ìƒíƒœ ì—…ë°ì´íŠ¸
    global_state["current_status"] = "âœï¸ ë©”ì¸ ì‘ê°€ê°€ ì´ì•¼ê¸°ë¥¼ ì§‘í•„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
    
    print("\n--- ë©”ì¸ ì‘ê°€ ì—ì´ì „íŠ¸ ì‘ë™ ---")
    story_so_far = "".join(state["story_parts"])
    discussion_str = "\n".join(state["discussion"])
    
    # [ìˆ˜ì •] ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ WRITER_LLM ì‚¬ìš©
    prompt = MAIN_WRITER_CONFIG["prompt_template"].format(
        world_name=MAIN_WRITER_CONFIG["world_name"],
        world_description=MAIN_WRITER_CONFIG["world_description"],
        story_so_far=story_so_far,
        discussion_str=discussion_str
    )
    response = WRITER_LLM.invoke(prompt)
    next_part = response.content.strip()
    print("--- ìƒì„±ëœ ì¥ë©´ ---")
    print(next_part)
    # ìƒì„±ëœ ì´ì•¼ê¸°ë¥¼ story_partsì— ì¶”ê°€í•˜ê³ , ë‹¤ìŒ ì‚¬ì´í´ì„ ìœ„í•´ í† ë¡  ë‚´ìš©ì€ ë¹„ì›ë‹ˆë‹¤.
    return {
        "story_parts": state["story_parts"] + ["\n\n" + next_part],
        "discussion": [], 
    }

# --- ë…¸ë“œ(Node)ë¡œ ì‚¬ìš©í•  í•¨ìˆ˜ ì •ì˜ ---

## ---ìºë¦­í„° ì¤‘ ëˆ„ê°€ í† ë¡  ì¤‘ ì˜ê²¬ì„ ì œì‹œí• ì§€ ê²½ìŸí•˜ëŠ” í•¨ìˆ˜---
VOTE_LLM = ChatGoogleGenerativeAI(
    model = CHARACTER_AGENT_CONFIG["vote_model"],
    temperature=CHARACTER_AGENT_CONFIG["vote_temperature"]
)

# [ì¶”ê°€] ì˜ê²¬ ìƒì„±ìš© LLM ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
OPINION_LLM = ChatGoogleGenerativeAI(
    model=CHARACTER_AGENT_CONFIG["opinion_model"],
    temperature=CHARACTER_AGENT_CONFIG["opinion_temperature"]
)

async def _get_character_vote(character_name:str, story_so_far:str, discussion: list[str]) -> Optional[str]:
    """ë‹¨ì¼ ì„œë¸Œ ì—ì´ì „íŠ¸ì˜ íˆ¬í‘œë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì–»ëŠ” í—¬í¼ í•¨ìˆ˜"""
    discussion_str = "\n".join(discussion)
    character_config = CHARACTERS[character_name]
    character_prompt = character_config["prompt"]
    prompt = CHARACTER_AGENT_CONFIG["prompt_templates"]["vote"].format(
        character_name=character_name,
        character_prompt=character_prompt,
        story_so_far=story_so_far,
        discussion_str=discussion_str
    )
    try:
        response = await VOTE_LLM.ainvoke(prompt)
        vote = response.content.strip() 
        if "ë„¤" in vote:
           # print(f"--- {character_name}ì˜ íˆ¬í‘œ: {vote} (ì„ íƒ!) ---")
            return character_name
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì–´ë–¤ ìºë¦­í„°ì—ì„œ ë¬¸ì œê°€ ìˆì—ˆëŠ”ì§€ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
        print(f"--- {character_name} íˆ¬í‘œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} ---")
        return None
    return None

## ---ê²½ìŸì„ í†µí•´ í–‰ë™í•  ìºë¦­í„°ë¥¼ ì„ íƒí•˜ëŠ” í•¨ìˆ˜---
async def race_for_action(state: GraphState) -> dict:
    """
    ëª¨ë“  ìºë¦­í„°ì—ê²Œ ë™ì‹œì— ë¬¼ì–´ë³´ê³ , ê°€ì¥ ë¨¼ì € 'ë„¤'ë¼ê³  ë‹µí•˜ëŠ” ìºë¦­í„°ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    """
    # [ì¶”ê°€] ìƒíƒœ ì—…ë°ì´íŠ¸
    global_state["current_status"] = "ğŸ‘€ ëˆˆì¹˜ ê²Œì„ ì¤‘... (ëˆ„ê°€ ë°œì–¸í• ì§€ ê²½ìŸ ì¤‘)"
    
    story_so_far = "".join(state["story_parts"])
    discussion = state["discussion"]
    characters = list(CHARACTERS.keys()) # ê²½ìŸì— ì°¸ì—¬í•  ìºë¦­í„° ëª©ë¡
    tasks = [asyncio.create_task(_get_character_vote(name, story_so_far, discussion)) for name in characters] 
    winner = None
    # asyncio.as_completedëŠ” ì‘ì—…ì´ ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    for future in asyncio.as_completed(tasks):
        try:
            result = await future
            if result:  # 'ë„¤'ë¼ê³  ë‹µí•œ ì²« ë²ˆì§¸ ìŠ¹ìë¥¼ ì°¾ìœ¼ë©´
                winner = result
                break # ì¦‰ì‹œ ë£¨í”„ë¥¼ ì¤‘ë‹¨í•˜ê³  ë” ì´ìƒ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
        except asyncio.CancelledError:
            pass # ì·¨ì†Œëœ ì‘ì—…ì€ ë¬´ì‹œí•©ë‹ˆë‹¤.        
    # ìŠ¹ìê°€ ê²°ì •ë˜ì—ˆìœ¼ë¯€ë¡œ, ì•„ì§ ì‹¤í–‰ ì¤‘ì¸ ë‚˜ë¨¸ì§€ ì‘ì—…ë“¤ì„ ëª¨ë‘ ì·¨ì†Œí•©ë‹ˆë‹¤.
    for task in tasks:
        if not task.done():
            task.cancel()      
    if not winner:
        print("--- í–‰ë™í•˜ë ¤ëŠ” ìºë¦­í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ---")
        return {"selected_character": "None"}
    return {"selected_character": winner}

## ---ì„ íƒëœ ìºë¦­í„°ê°€ í† ë¡ ì— ëŒ€í•œ ì˜ê²¬ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜---
def generate_character_opinion(state: GraphState) -> dict:
    """ì„ íƒëœ ìºë¦­í„°ê°€ í† ë¡ ì— ëŒ€í•œ ì˜ê²¬ì„ ìƒì„±í•˜ê³  discussion ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    character_name = state["selected_character"]
    
    # [ì¶”ê°€] ìƒíƒœ ì—…ë°ì´íŠ¸
    global_state["current_status"] = f"ğŸ—£ï¸ '{character_name}' ì‘ê°€ê°€ ë°œì–¸ì„ ì •ë¦¬í•˜ëŠ” ì¤‘..."

    if not character_name or character_name == "None":
        return {}
   # print(f"\n--- í† ë¡  ë°œì–¸: {character_name} ---")
    story_so_far = "".join(state["story_parts"])
    discussion = state["discussion"]
    discussion_str = "\n".join(discussion)
    # ìºë¦­í„° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    character_config = CHARACTERS[character_name]
    
    # [ìˆ˜ì •] ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ OPINION_LLM ì‚¬ìš©
    prompt = CHARACTER_AGENT_CONFIG["prompt_templates"]["generate_opinion"].format(
        character_name=character_name,
        character_prompt=character_config["prompt"],
        story_so_far=story_so_far,
        discussion_str=discussion_str
    )
    response = OPINION_LLM.invoke(prompt)
    opinion = f"**{character_name} specialist writer**: {response.content.strip()}" 
    print(opinion)
    # ìƒì„±ëœ ì˜ê²¬ì„ discussion ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    return {"discussion": discussion + [opinion]}

# [ìˆ˜ì •ë¨] ì‚¬ìš©ì ì…ë ¥ì„ ë¹„ë™ê¸°ë¡œ ê¸°ë‹¤ë¦¬ëŠ” ë…¸ë“œ
async def check_continuation(state: GraphState):
    print("\nâ³ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ [ê³„ì†í•˜ê¸°] ë˜ëŠ” [ì¢…ë£Œ]ë¥¼ ì„ íƒí•˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
    
    # [ì¶”ê°€] ìƒíƒœ ì—…ë°ì´íŠ¸
    global_state["current_status"] = "â³ ë‹¹ì‹ ì˜ ì„ íƒì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤."

    # 1. ì›¹ UIì— ë²„íŠ¼ì„ ë„ìš°ë¼ê³  ì‹ í˜¸ë¥¼ ë³´ëƒ„
    global_state["waiting_for_input"] = True
    global_state["user_decision"] = None # ì´ì „ ê²°ì • ì´ˆê¸°í™”

    # 2. ì›¹ì—ì„œ ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œê¹Œì§€ ë¬´í•œ ëŒ€ê¸° (0.5ì´ˆ ê°„ê²© ì²´í¬)
    while global_state["user_decision"] is None:
        await asyncio.sleep(0.5)

    # 3. ê²°ì •ì´ ë‚´ë ¤ì§€ë©´ ì‹ í˜¸ë¥¼ ë„ê³  ì§„í–‰
    decision = global_state["user_decision"]
    global_state["waiting_for_input"] = False
    
    print(f"âœ… ì‚¬ìš©ì ì„ íƒ í™•ì¸: {decision}")
    
    # stateì— ê²°ì •ì„ ì €ì¥í•´ì„œ ë¼ìš°í„°ê°€ íŒë‹¨í•˜ê²Œ í•¨ (ì„ íƒ ì‚¬í•­)
    return {"user_decision": decision}

# [ì¶”ê°€ë¨] ë¼ìš°íŒ… ë¡œì§
def route_continuation(state: GraphState):
    # check_continuation ë…¸ë“œì—ì„œ ê²°ì •ëœ ì‚¬í•­ì„ global_stateì—ì„œ í™•ì¸
    decision = global_state.get("user_decision")
    
    if decision == "continue":
        return "race_for_action"
    else:
        return END








